{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2UoMFE3H8ti",
        "outputId": "1f0ee3fe-f05e-4ac0-b831-c0506bdf6a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '/content/drive/MyDrive/MontgomerySubdata'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6S3IMhsIAyG",
        "outputId": "a5d49ef0-7b52-418a-d365-5f876c3d8644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CHNCXR_0056_0.png', 'CHNCXR_0047_0.png', 'CHNCXR_0055_0.png', 'CHNCXR_0037_0.png', 'CHNCXR_0028_0.png', 'CHNCXR_0048_0.png', 'CHNCXR_0051_0.png', 'CHNCXR_0012_0.png', 'CHNCXR_0044_0.png', 'CHNCXR_0036_0.png', 'CHNCXR_0031_0.png', 'CHNCXR_0032_0.png', 'CHNCXR_0025_0.png', 'CHNCXR_0011_0.png', 'CHNCXR_0060_0.png', 'CHNCXR_0053_0.png', 'CHNCXR_0045_0.png', 'CHNCXR_0027_0.png', 'CHNCXR_0016_0.png', 'CHNCXR_0046_0.png', 'CHNCXR_0042_0.png', 'CHNCXR_0039_0.png', 'CHNCXR_0052_0.png', 'CHNCXR_0054_0.png', 'CHNCXR_0034_0.png', 'CHNCXR_0041_0.png', 'CHNCXR_0038_0.png', 'CHNCXR_0035_0.png', 'CHNCXR_0019_0.png', 'CHNCXR_0050_0.png', 'CHNCXR_0033_0.png', 'CHNCXR_0059_0.png', 'CHNCXR_0014_0.png', 'CHNCXR_0049_0.png', 'CHNCXR_0021_0.png', 'CHNCXR_0010_0.png', 'CHNCXR_0018_0.png', 'CHNCXR_0058_0.png', 'CHNCXR_0026_0.png', 'CHNCXR_0030_0.png', 'CHNCXR_0017_0.png', 'CHNCXR_0015_0.png', 'CHNCXR_0029_0.png', 'CHNCXR_0013_0.png', 'CHNCXR_0043_0.png', 'CHNCXR_0020_0.png', 'CHNCXR_0057_0.png', 'CHNCXR_0023_0.png', 'CHNCXR_0040_0.png', 'CHNCXR_0024_0.png', 'CHNCXR_0022_0.png', 'MCUCXR_0011_0.png', 'MCUCXR_0015_0.png', 'MCUCXR_0016_0.png', 'MCUCXR_0013_0.png', 'MCUCXR_0024_0.png', 'MCUCXR_0030_0.png', 'MCUCXR_0046_0.png', 'MCUCXR_0049_0.png', 'MCUCXR_0045_0.png', 'MCUCXR_0028_0.png', 'MCUCXR_0029_0.png', 'MCUCXR_0043_0.png', 'MCUCXR_0042_0.png', 'MCUCXR_0019_0.png', 'MCUCXR_0051_0.png', 'MCUCXR_0021_0.png', 'MCUCXR_0048_0.png', 'MCUCXR_0041_0.png', 'MCUCXR_0044_0.png', 'MCUCXR_0026_0.png', 'MCUCXR_0040_0.png', 'MCUCXR_0035_0.png', 'MCUCXR_0020_0.png', 'MCUCXR_0027_0.png', 'MCUCXR_0038_0.png', 'MCUCXR_0047_0.png', 'MCUCXR_0017_0.png', 'MCUCXR_0022_0.png', 'MCUCXR_0031_0.png', 'MCUCXR_0023_0.png', 'CHNCXR_0328_1.png', 'CHNCXR_0349_1.png', 'CHNCXR_0353_1.png', 'CHNCXR_0361_1.png', 'CHNCXR_0346_1.png', 'CHNCXR_0355_1.png', 'CHNCXR_0367_1.png', 'CHNCXR_0340_1.png', 'CHNCXR_0341_1.png', 'CHNCXR_0357_1.png', 'CHNCXR_0362_1.png', 'CHNCXR_0337_1.png', 'CHNCXR_0352_1.png', 'CHNCXR_0333_1.png', 'CHNCXR_0327_1.png', 'CHNCXR_0356_1.png', 'CHNCXR_0336_1.png', 'CHNCXR_0347_1.png', 'CHNCXR_0329_1.png', 'CHNCXR_0350_1.png', 'CHNCXR_0335_1.png', 'CHNCXR_0343_1.png', 'CHNCXR_0339_1.png', 'CHNCXR_0360_1.png', 'CHNCXR_0348_1.png', 'CHNCXR_0358_1.png', 'CHNCXR_0359_1.png', 'CHNCXR_0344_1.png', 'CHNCXR_0338_1.png', 'CHNCXR_0345_1.png', 'CHNCXR_0364_1.png', 'CHNCXR_0365_1.png', 'CHNCXR_0366_1.png', 'CHNCXR_0351_1.png', 'CHNCXR_0331_1.png', 'CHNCXR_0342_1.png', 'CHNCXR_0354_1.png', 'CHNCXR_0334_1.png', 'CHNCXR_0363_1.png', 'CHNCXR_0332_1.png', 'CHNCXR_0330_1.png', 'MCUCXR_0338_1.png', 'MCUCXR_0316_1.png', 'MCUCXR_0258_1.png', 'MCUCXR_0331_1.png', 'MCUCXR_0126_1.png', 'MCUCXR_0213_1.png', 'MCUCXR_0203_1.png', 'MCUCXR_0166_1.png', 'MCUCXR_0294_1.png', 'MCUCXR_0282_1.png', 'MCUCXR_0251_1.png', 'MCUCXR_0144_1.png', 'MCUCXR_0309_1.png', 'MCUCXR_0228_1.png', 'MCUCXR_0170_1.png', 'MCUCXR_0313_1.png', 'MCUCXR_0195_1.png', 'MCUCXR_0348_1.png', 'MCUCXR_0254_1.png', 'MCUCXR_0140_1.png', 'MCUCXR_0141_1.png', 'MCUCXR_0173_1.png', 'MCUCXR_0150_1.png', 'MCUCXR_0264_1.png', 'MCUCXR_0311_1.png', 'MCUCXR_0266_1.png', 'MCUCXR_0162_1.png', 'MCUCXR_0255_1.png', 'MCUCXR_0253_1.png', 'MCUCXR_0334_1.png', 'MCUCXR_0218_1.png', 'MCUCXR_0275_1.png', 'MCUCXR_0194_1.png', 'MCUCXR_0301_1.png', 'MCUCXR_0243_1.png', 'MCUCXR_0142_1.png', 'MCUCXR_0223_1.png', 'MCUCXR_0188_1.png', 'MCUCXR_0289_1.png', 'MCUCXR_0196_1.png', 'MCUCXR_0182_1.png', 'MCUCXR_0375_1.png', 'MCUCXR_0390_1.png', 'MCUCXR_0350_1.png', 'MCUCXR_0367_1.png', 'MCUCXR_0383_1.png', 'MCUCXR_0354_1.png', 'MCUCXR_0362_1.png', 'MCUCXR_0369_1.png', 'MCUCXR_0387_1.png', 'MCUCXR_0352_1.png', 'MCUCXR_0393_1.png', 'MCUCXR_0372_1.png', 'MCUCXR_0399_1.png', 'MCUCXR_0104_1.png', 'MCUCXR_0108_1.png', 'MCUCXR_0113_1.png', 'CHNCXR_0302_0.png', 'CHNCXR_0310_0.png', 'CHNCXR_0314_0.png', 'CHNCXR_0317_0.png', 'CHNCXR_0306_0.png', 'CHNCXR_0304_0.png', 'CHNCXR_0315_0.png', 'CHNCXR_0309_0.png', 'CHNCXR_0307_0.png', 'CHNCXR_0308_0.png', 'CHNCXR_0311_0.png', 'CHNCXR_0318_0.png', 'CHNCXR_0316_0.png', 'CHNCXR_0303_0.png', 'CHNCXR_0312_0.png', 'CHNCXR_0305_0.png', 'CHNCXR_0313_0.png', 'CHNCXR_0319_0.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch -\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "IDGuphwDIIbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "images_directory = \"/content/drive/MyDrive/MontgomerySubdata\"\n",
        "for filename in glob.glob(images_directory+\"/*.png\"):\n",
        "    image = cv2.imread(filename)\n",
        "    image = cv2.resize(image,(32,32))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    image = image/255\n",
        "    images.append(image)\n",
        "    label = 1 if filename[-6:-4] == \"_1\" else 0\n",
        "    labels.append(label)\n",
        "np.random.shuffle(labels)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-haT9_5INoZ",
        "outputId": "28d33b83-efb9-48f2-d240-293e9621ac2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I assigned the images and labels to variables x and y. I have a total of 197 examples."
      ],
      "metadata": {
        "id": "COe9KNrpS5fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "x = x.reshape(197, 1024)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "ID4jisenkjp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3e537b-356b-4f60-f541-c67503c7c6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(197, 1024)\n",
            "(197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=.25)\n"
      ],
      "metadata": {
        "id": "r5EShRqxg16L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I created a class called Data. The keyword self is a concept that allows us to access the objects (X, y) that we have instantiated from within the class.\n",
        "\n",
        "The init method is used when the class is created. We define the class parameters here. When we use self.X, it retrieves the X within the class, and whatever we assign to that X within the function, it will operate on the assigned X. Here, we used the torch.from_numpy function to convert the X data into tensors.\n",
        "\n",
        "The getitem method, with the position parameter it receives, tells us which indexed value to return.\n",
        "\n",
        "If we want a value to be returned when we place an instance of our class inside len, we apply a method named len within our class.\n",
        "\n",
        "The enumerate function is used to enumerate objects, meaning it returns both the element and its index in a list."
      ],
      "metadata": {
        "id": "_jJDB-EgTIkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Convert data to torch tensors\n",
        "class Data(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y.astype(np.float32).reshape(-1, 1))\n",
        "        self.len = self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Instantiate training and test data\n",
        "train_data = Data(x_train, y_train)\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data = Data(x_test, y_test)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for batch, (X, y) in enumerate(train_dataloader):\n",
        "    print(f\"Batch: {batch+1}\")\n",
        "    print(f\"X shape: {X.shape}\")\n",
        "    print(f\"y shape: {y.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NBEuEGyt-Zk",
        "outputId": "2d6811c5-5d6a-40cb-dc45-56909faf8245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 1\n",
            "X shape: torch.Size([128, 1024])\n",
            "y shape: torch.Size([128, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a subclass inherits from a superclass and defines its own init method, the variables from the superclass are not preserved; they get overridden. The super().init function ensures that the variables from the superclass are preserved."
      ],
      "metadata": {
        "id": "qo4iILX1YmvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "input_dim = 1024\n",
        "input_dim2 = 128\n",
        "\n",
        "hidden_dim = 128\n",
        "hidden_dim2 = 64\n",
        "output_dim = 1\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        nn.init.kaiming_uniform_(self.layer_1.weight, nonlinearity=\"relu\")\n",
        "        self.layer_2 = nn.Linear(input_dim2, hidden_dim2)\n",
        "        nn.init.kaiming_uniform_(self.layer_2.weight, nonlinearity=\"relu\")\n",
        "        self.layer_3 = nn.Linear(64, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.relu(self.layer_1(x))\n",
        "        x = torch.nn.functional.relu(self.layer_2(x))\n",
        "        x = torch.nn.functional.sigmoid(self.layer_3(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "SShXffAZfLla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork(input_dim, hidden_dim, output_dim)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHGDA1c_hkA_",
        "outputId": "cbf51a84-a9c5-45d2-cd3d-aa0d9f028f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layer_1): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (layer_2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (layer_3): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device(\"cpu\")\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on device:\", device_gpu)\n",
        "model = NeuralNetwork(input_dim, hidden_dim, output_dim).to(device_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMQbYy4AruzN",
        "outputId": "2507eea7-4ff7-46a3-9e6e-438e293303c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = torch.from_numpy(x_train.reshape(-1, 32*32)).float().to(device_gpu)\n",
        "labels_train = torch.from_numpy(y_train.reshape(-1, 1)).float().to(device_gpu)"
      ],
      "metadata": {
        "id": "X9RdqzOntV3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "uEtQe65owAup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "learning_rate = 0.001\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "# Calculate and print the elapsed time for CPU\n",
        "elapsed_time_cpu = time.time() - start_time\n",
        "print(\"Elapsed time for CPU:\", elapsed_time_cpu, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-aXUjTfrzEV",
        "outputId": "fe19da74-a454-4c76-8c45-b91c78ac269a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time for CPU: 0.000518798828125 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(0, len(X), batch_size):\n",
        "        Xbatch = X[i:i+batch_size]\n",
        "        y_pred = model(Xbatch)\n",
        "        ybatch = y[i:i+batch_size]\n",
        "        loss = loss_fn(y_pred, ybatch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Finished epoch {epoch}, latest loss {loss}')"
      ],
      "metadata": {
        "id": "RgQptJcGatp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(X)\n",
        "accuracy = (y_pred.round() == y).float().mean()\n",
        "print(f\"Accuracy {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWJ0sO2dbMnr",
        "outputId": "2c9fc644-d3ef-474e-e470-3cf15ff2e0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 0.796875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# Calculate and print the elapsed time for GPU\n",
        "elapsed_time_gpu = time.time() - start_time\n",
        "print(\"Elapsed time for GPU:\", elapsed_time_gpu, \"seconds.\")"
      ],
      "metadata": {
        "id": "9mcQzQn0hnjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea42a809-6a1b-4230-ddfe-9a82057d8675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time for GPU: 4.100799560546875e-05 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = torch.from_numpy(x_test.reshape(-1, 32*32)).float().to(device_gpu)\n",
        "labels_test = torch.from_numpy(y_test.reshape(-1, 1)).float().to(device_gpu)"
      ],
      "metadata": {
        "id": "8qTNL_zoyIkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the data for the bar plot\n",
        "elapsed_times = [elapsed_time_cpu, elapsed_time_gpu]\n",
        "devices = ['CPU', 'GPU']\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = (y_pred == y_test)\n",
        "total = y_test(0)\n",
        "accuracy = correct / total\n",
        "print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
        "# Create the bar plot\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(devices, elapsed_times)\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Device')\n",
        "ax.set_ylabel('Elapsed Time (s)')\n",
        "ax.set_title('Training Time Comparison')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "plt.savefig('timing.png')"
      ],
      "metadata": {
        "id": "oij4FJ97hnkp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "0adb9e75-fc3f-4674-8e3b-41e3df01e1ac",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-144-aec3d7810081>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: {:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
          ]
        }
      ]
    }
  ]
}